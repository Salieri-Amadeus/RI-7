{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21615719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrait_tools as pt\n",
    "import feature_engineering as fe  \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776886a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.00      0.00      0.00        66\n",
      "          FD       0.58      0.35      0.44       193\n",
      "          FQ       0.36      0.08      0.13        65\n",
      "          GG       0.63      0.46      0.54        41\n",
      "          IR       0.67      0.24      0.35        84\n",
      "          JK       1.00      0.08      0.15        12\n",
      "          NF       0.50      0.02      0.04        47\n",
      "           O       0.00      0.00      0.00         2\n",
      "          OQ       0.98      0.97      0.97       221\n",
      "          PA       0.82      0.86      0.84       365\n",
      "          PF       0.71      0.41      0.52        97\n",
      "          RQ       0.29      0.04      0.07        49\n",
      "\n",
      "   micro avg       0.80      0.55      0.65      1242\n",
      "   macro avg       0.54      0.29      0.34      1242\n",
      "weighted avg       0.69      0.55      0.58      1242\n",
      " samples avg       0.68      0.61      0.63      1242\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.00      0.00      0.00        46\n",
      "          FD       0.76      0.38      0.51       226\n",
      "          FQ       0.61      0.19      0.29        59\n",
      "          GG       0.64      0.36      0.46        25\n",
      "          IR       0.62      0.23      0.34       103\n",
      "          JK       0.00      0.00      0.00        12\n",
      "          NF       0.00      0.00      0.00        54\n",
      "           O       0.00      0.00      0.00         4\n",
      "          OQ       0.98      0.95      0.96       226\n",
      "          PA       0.81      0.87      0.84       364\n",
      "          PF       0.81      0.40      0.54        87\n",
      "          RQ       1.00      0.12      0.21        51\n",
      "\n",
      "   micro avg       0.83      0.56      0.67      1257\n",
      "   macro avg       0.52      0.29      0.35      1257\n",
      "weighted avg       0.73      0.56      0.60      1257\n",
      " samples avg       0.70      0.61      0.64      1257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# every positive label is a separate column\n",
    "onehot_cols = ['CQ','FD','FQ','GG','IR','JK','NF','O','OQ','PA','PF','RQ']\n",
    "mlb = MultiLabelBinarizer(classes=onehot_cols)\n",
    "\n",
    "def load_dataset(path):\n",
    "    labels = []\n",
    "    features = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                parts = line.strip().split()\n",
    "                raw_labels = parts[0].split('_')  \n",
    "                feat = list(map(float, parts[1:]))\n",
    "                labels.append(raw_labels)\n",
    "                features.append(feat)\n",
    "    # transform labels to one-hot encoding\n",
    "    y = mlb.fit_transform(labels)\n",
    "    X = np.array(features)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train, y_train = load_dataset(\"../data/msdialog/train_features.tsv\")\n",
    "X_valid, y_valid = load_dataset(\"../data/msdialog/valid_features.tsv\")\n",
    "X_test, y_test   = load_dataset(\"../data/msdialog/test_features.tsv\")\n",
    "\n",
    "# construct a multi-label random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf = MultiOutputClassifier(rf)\n",
    "\n",
    "# train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# validset prediction and results\n",
    "y_valid_pred = clf.predict(X_valid)\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_valid, y_valid_pred, target_names=onehot_cols, zero_division=0))\n",
    "\n",
    "# testset prediction and results\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=onehot_cols, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0edb6e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.00      0.00      0.00        66\n",
      "          FD       0.53      0.34      0.41       193\n",
      "          FQ       0.50      0.12      0.20        65\n",
      "          GG       0.71      0.49      0.58        41\n",
      "          IR       0.54      0.15      0.24        84\n",
      "          JK       0.33      0.08      0.13        12\n",
      "          NF       0.27      0.06      0.10        47\n",
      "           O       0.00      0.00      0.00         2\n",
      "          OQ       0.98      0.97      0.97       221\n",
      "          PA       0.79      0.86      0.82       365\n",
      "          PF       0.69      0.49      0.57        97\n",
      "          RQ       0.57      0.08      0.14        49\n",
      "\n",
      "   micro avg       0.76      0.56      0.64      1242\n",
      "   macro avg       0.49      0.30      0.35      1242\n",
      "weighted avg       0.66      0.56      0.58      1242\n",
      " samples avg       0.67      0.62      0.63      1242\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.00      0.00      0.00        46\n",
      "          FD       0.73      0.41      0.53       226\n",
      "          FQ       0.71      0.20      0.32        59\n",
      "          GG       0.65      0.52      0.58        25\n",
      "          IR       0.60      0.17      0.27       103\n",
      "          JK       0.25      0.08      0.12        12\n",
      "          NF       0.50      0.04      0.07        54\n",
      "           O       0.00      0.00      0.00         4\n",
      "          OQ       0.98      0.95      0.96       226\n",
      "          PA       0.81      0.88      0.84       364\n",
      "          PF       0.78      0.37      0.50        87\n",
      "          RQ       0.64      0.14      0.23        51\n",
      "\n",
      "   micro avg       0.82      0.57      0.67      1257\n",
      "   macro avg       0.55      0.31      0.37      1257\n",
      "weighted avg       0.74      0.57      0.61      1257\n",
      " samples avg       0.70      0.62      0.64      1257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# ada boost classifier\n",
    "base_estimator = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "clf = MultiOutputClassifier(base_estimator)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_valid_pred = clf.predict(X_valid)\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_valid, y_valid_pred, target_names=onehot_cols, zero_division=0))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=onehot_cols, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f230cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.00      0.00      0.00        66\n",
      "          FD       0.56      0.31      0.39       193\n",
      "          FQ       0.00      0.00      0.00        65\n",
      "          GG       0.58      0.27      0.37        41\n",
      "          IR       0.43      0.04      0.07        84\n",
      "          JK       0.00      0.00      0.00        12\n",
      "          NF       1.00      0.02      0.04        47\n",
      "           O       0.00      0.00      0.00         2\n",
      "          OQ       0.97      0.97      0.97       221\n",
      "          PA       0.76      0.87      0.81       365\n",
      "          PF       0.82      0.46      0.59        97\n",
      "          RQ       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.79      0.52      0.63      1242\n",
      "   macro avg       0.43      0.24      0.27      1242\n",
      "weighted avg       0.63      0.52      0.54      1242\n",
      " samples avg       0.65      0.58      0.60      1242\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.00      0.00      0.00        46\n",
      "          FD       0.70      0.31      0.43       226\n",
      "          FQ       0.00      0.00      0.00        59\n",
      "          GG       0.67      0.24      0.35        25\n",
      "          IR       0.62      0.05      0.09       103\n",
      "          JK       0.00      0.00      0.00        12\n",
      "          NF       0.00      0.00      0.00        54\n",
      "           O       0.00      0.00      0.00         4\n",
      "          OQ       0.97      0.95      0.96       226\n",
      "          PA       0.77      0.87      0.82       364\n",
      "          PF       0.87      0.38      0.53        87\n",
      "          RQ       0.00      0.00      0.00        51\n",
      "\n",
      "   micro avg       0.82      0.51      0.63      1257\n",
      "   macro avg       0.38      0.23      0.26      1257\n",
      "weighted avg       0.65      0.51      0.54      1257\n",
      " samples avg       0.65      0.57      0.59      1257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SVM\n",
    "clf = OneVsRestClassifier(LinearSVC(random_state=42, max_iter=5000))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_valid_pred = clf.predict(X_valid)\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_valid, y_valid_pred, target_names=onehot_cols, zero_division=0))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=onehot_cols, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea67dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.22      0.33      0.27        66\n",
      "          FD       0.41      0.32      0.36       193\n",
      "          FQ       0.26      0.28      0.27        65\n",
      "          GG       0.15      0.95      0.25        41\n",
      "          IR       0.21      0.74      0.32        84\n",
      "          JK       0.03      1.00      0.05        12\n",
      "          NF       0.16      0.32      0.21        47\n",
      "           O       0.01      1.00      0.01         2\n",
      "          OQ       0.93      0.97      0.95       221\n",
      "          PA       0.69      0.87      0.77       365\n",
      "          PF       0.32      0.81      0.46        97\n",
      "          RQ       0.24      0.59      0.35        49\n",
      "\n",
      "   micro avg       0.31      0.70      0.43      1242\n",
      "   macro avg       0.30      0.68      0.36      1242\n",
      "weighted avg       0.52      0.70      0.57      1242\n",
      " samples avg       0.43      0.74      0.50      1242\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.20      0.50      0.29        46\n",
      "          FD       0.38      0.30      0.34       226\n",
      "          FQ       0.23      0.32      0.27        59\n",
      "          GG       0.10      0.96      0.19        25\n",
      "          IR       0.26      0.70      0.38       103\n",
      "          JK       0.02      0.83      0.05        12\n",
      "          NF       0.16      0.31      0.21        54\n",
      "           O       0.01      0.50      0.01         4\n",
      "          OQ       0.92      0.95      0.93       226\n",
      "          PA       0.69      0.85      0.76       364\n",
      "          PF       0.29      0.75      0.41        87\n",
      "          RQ       0.20      0.49      0.28        51\n",
      "\n",
      "   micro avg       0.31      0.67      0.42      1257\n",
      "   macro avg       0.29      0.62      0.34      1257\n",
      "weighted avg       0.51      0.67      0.56      1257\n",
      " samples avg       0.43      0.71      0.49      1257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# GaussianNB\n",
    "clf = OneVsRestClassifier(GaussianNB())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_valid_pred = clf.predict(X_valid)\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_valid, y_valid_pred, target_names=onehot_cols, zero_division=0))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=onehot_cols, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7344c07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.00      0.00      0.00        66\n",
      "          FD       0.43      0.21      0.28       193\n",
      "          FQ       0.60      0.05      0.09        65\n",
      "          GG       0.62      0.24      0.35        41\n",
      "          IR       0.41      0.11      0.17        84\n",
      "          JK       0.20      0.08      0.12        12\n",
      "          NF       0.00      0.00      0.00        47\n",
      "           O       0.00      0.00      0.00         2\n",
      "          OQ       0.96      0.87      0.91       221\n",
      "          PA       0.66      0.85      0.74       365\n",
      "          PF       0.71      0.51      0.59        97\n",
      "          RQ       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.69      0.50      0.58      1242\n",
      "   macro avg       0.38      0.24      0.27      1242\n",
      "weighted avg       0.57      0.50      0.50      1242\n",
      " samples avg       0.60      0.55      0.56      1242\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.00      0.00      0.00        46\n",
      "          FD       0.46      0.19      0.27       226\n",
      "          FQ       0.00      0.00      0.00        59\n",
      "          GG       0.40      0.24      0.30        25\n",
      "          IR       0.40      0.08      0.13       103\n",
      "          JK       0.17      0.08      0.11        12\n",
      "          NF       0.00      0.00      0.00        54\n",
      "           O       0.00      0.00      0.00         4\n",
      "          OQ       0.95      0.85      0.90       226\n",
      "          PA       0.64      0.87      0.74       364\n",
      "          PF       0.63      0.38      0.47        87\n",
      "          RQ       0.00      0.00      0.00        51\n",
      "\n",
      "   micro avg       0.68      0.48      0.56      1257\n",
      "   macro avg       0.30      0.22      0.24      1257\n",
      "weighted avg       0.53      0.48      0.47      1257\n",
      " samples avg       0.59      0.53      0.54      1257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class MyMultiLabelKNN:\n",
    "    def __init__(self, k=10, threshold=0.5):\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.k)\n",
    "        self.nn.fit(X)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        distances, indices = self.nn.kneighbors(X_test)\n",
    "        y_pred = []\n",
    "\n",
    "        for neighbors in indices:\n",
    "            neighbor_labels = self.y_train[neighbors]\n",
    "            label_counts = np.sum(neighbor_labels, axis=0)\n",
    "            label_pred = (label_counts / self.k) >= self.threshold\n",
    "            y_pred.append(label_pred.astype(int))\n",
    "\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "clf = MyMultiLabelKNN(k=10, threshold=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_valid_pred = clf.predict(X_valid)\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_valid, y_valid_pred, target_names=onehot_cols, zero_division=0))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=onehot_cols, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Group Evaluation\n",
    "def evaluate_feature_group(X_train, y_train, X_valid, y_valid, indices, group_name):\n",
    "    X_train_sub = X_train[:, indices]\n",
    "    X_valid_sub = X_valid[:, indices]\n",
    "\n",
    "    clf = OneVsRestClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    clf.fit(X_train_sub, y_train)\n",
    "    y_pred = clf.predict(X_valid_sub)\n",
    "\n",
    "    micro = f1_score(y_valid, y_pred, average='micro')\n",
    "    macro = f1_score(y_valid, y_pred, average='macro')\n",
    "    print(f\"{group_name:<15s} → Micro-F1: {micro:.4f}, Macro-F1: {macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde87464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group features\n",
    "idx_content = list(range(1, 10))           # init_sim to 5W1H\n",
    "idx_struct = list(range(10, 16))           # abs_pos to is_starter\n",
    "idx_sentiment = list(range(16, 24))       # thx to lexicon count\n",
    "idx_all = idx_content + idx_struct + idx_sentiment\n",
    "idx_con_str = idx_content + idx_struct\n",
    "idx_con_sent = idx_content + idx_sentiment\n",
    "idx_str_sent = idx_struct + idx_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb60d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content         → Micro-F1: 0.2898, Macro-F1: 0.1666\n",
      "Structural      → Micro-F1: 0.5696, Macro-F1: 0.2557\n",
      "Sentiment       → Micro-F1: 0.2721, Macro-F1: 0.1484\n",
      "Content+Struct  → Micro-F1: 0.6187, Macro-F1: 0.2927\n",
      "Content+Sent    → Micro-F1: 0.3723, Macro-F1: 0.2019\n",
      "Struct+Sent     → Micro-F1: 0.6278, Macro-F1: 0.3035\n",
      "All             → Micro-F1: 0.6495, Macro-F1: 0.3331\n"
     ]
    }
   ],
   "source": [
    "# evaluate feature groups\n",
    "evaluate_feature_group(X_train, y_train, X_valid, y_valid, idx_content, \"Content\")\n",
    "evaluate_feature_group(X_train, y_train, X_valid, y_valid, idx_struct, \"Structural\")\n",
    "evaluate_feature_group(X_train, y_train, X_valid, y_valid, idx_sentiment, \"Sentiment\")\n",
    "evaluate_feature_group(X_train, y_train, X_valid, y_valid, idx_con_str, \"Content+Struct\")\n",
    "evaluate_feature_group(X_train, y_train, X_valid, y_valid, idx_con_sent, \"Content+Sent\")\n",
    "evaluate_feature_group(X_train, y_train, X_valid, y_valid, idx_str_sent, \"Struct+Sent\")\n",
    "evaluate_feature_group(X_train, y_train, X_valid, y_valid, idx_all, \"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8dce6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Normalized Feature Importances (max=1.0):\n",
      " 1. init_sim        → 1.0000\n",
      " 2. abs_pos         → 0.9399\n",
      " 3. thread_sim      → 0.7594\n",
      " 4. norm_pos        → 0.7006\n",
      " 5. sent_pos        → 0.6578\n",
      " 6. sent_neu        → 0.6480\n",
      " 7. length          → 0.5818\n",
      " 8. unique_len      → 0.5225\n",
      " 9. is_starter      → 0.5221\n",
      "10. stemmed_len     → 0.5098\n",
      "11. sent_neg        → 0.4044\n",
      "12. question_mark   → 0.2206\n",
      "13. has_thanks      → 0.1446\n",
      "14. who             → 0.1158\n",
      "15. what            → 0.1044\n",
      "16. exclam_mark     → 0.1039\n",
      "17. duplicate       → 0.0916\n",
      "18. how             → 0.0887\n",
      "19. lexicon_pos     → 0.0773\n",
      "20. why             → 0.0534\n",
      "21. verbal_feedback → 0.0508\n",
      "22. when            → 0.0464\n",
      "23. lexicon_neg     → 0.0390\n",
      "24. where           → 0.0349\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# feature names list\n",
    "feature_names = [\n",
    "    \"init_sim\", \"thread_sim\", \"question_mark\", \"duplicate\",\n",
    "    \"who\", \"what\", \"when\", \"where\", \"why\", \"how\",\n",
    "    \"abs_pos\", \"norm_pos\", \"length\", \"unique_len\", \"stemmed_len\", \"is_starter\",\n",
    "    \"has_thanks\", \"exclam_mark\", \"verbal_feedback\",\n",
    "    \"sent_neg\", \"sent_neu\", \"sent_pos\",\n",
    "    \"lexicon_pos\", \"lexicon_neg\"\n",
    "]\n",
    "\n",
    "# use label powerset for multi-label classification\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lp = LabelPowerset(classifier=rf)\n",
    "lp.fit(X_train, y_train)\n",
    "\n",
    "# classifier and normalized feature importances\n",
    "importances = lp.classifier.feature_importances_\n",
    "normalized = importances / np.max(importances)\n",
    "sorted_idx = np.argsort(normalized)[::-1]\n",
    "\n",
    "print(\"🔍 Normalized Feature Importances (max=1.0):\")\n",
    "for rank, idx in enumerate(sorted_idx, 1):\n",
    "    print(f\"{rank:>2}. {feature_names[idx]:<15} → {normalized[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c88c493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
